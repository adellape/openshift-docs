[[appguides-python-getting-started]]
= Python Advanced Deployment
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:

toc::[]

The `python` source-to-image (S2I) builders provide a number of different ways of deploying a Python application. You can use the bundled support for hosting a WSGI application via Gunicorn, or you can choose to use other WSGI servers such as mod_wsgi-express and uWSGI. Prefer to run asynchronous event based applications, you can use frameworks such as Tornado, Twisted, or newer asyncio based systems.

=== Automatic Detection

The basis for determining which deployment mechanism is used is based on the following detection algorithm:

1. If a Python code file named `app.py` exists in the top level directory of the source code repository, it will be executed as a Python script. You can run from `app.py` any Python web server or application framework, so long as it accepts inbound HTTP connections on port 8080. If a Python web server does not provide a way of being started up by importing a Python module and invoking it via an API call, you can use `exec` functions from the `os` module to execute a separate command line program.

2. If the `gunicorn` package has been installed via the `requirements.txt` or `setup.py` files, and a `wsgi.py` file is located in the top level directory of the source code repository, or a sub directory down to at most two levels, the Gunicorn WSGI server will be used to host the WSGI application. When located in a sub directory, the `wsgi.py` file must be part of a Python package and will be imported by its module path, rather than by file system path. The name of the WSGI application entry point callable contained in the `wsgi.py` file must be called `application`.

3. If the `gunicorn` package has been installed via the `requirements.txt` or `setup.py` files, but a `wsgi.py` file could not be found, and a `setup.py` file had been used, the name of the package installed by the `setup.py` will be taken to contain the WSGI application entry point callable.

4. If the `Django` package has been installed via the `requirements.txt` or `setup.py` files, and a `manage.py` file is located in the top level directory of the source code repository, or an immediate sub directory, it will be assumed that a Django based application is being used. For this case the Django application will be started using the Django development server. As the Django development server is not suitable for production use, this method should only be relied on for initial setup or testing.

For (1), the name of the `app.py` file can be overridden by setting the `APP_FILE` environment variable.

For (2) and (3), the search for a module containing the WSGI application entry point callable will be skipped if the module path is set using the `APP_MODULE` environment variable. If specifying the module containing the WSGI application entry point callable in this way, you must still have installed the `gunicorn` package via the `requirements.txt` or `setup.py` files.

=== Application Logging

OpenShift expects that all logging from your application, or a web server, is directed to the console (standard output/error stream). If the web server or application framework logs to files, the log output will not be available through OpenShift.

When the bundled support for hosting a WSGI application via Gunicorn is used, the source-to-image builder scripts will ensure that Gunicorn is started with the appropriate options to direct any log output to the console so that it can be captured by OpenShift.

If you are using a different WSGI server or application framework with its own bundled web server, you will need to ensure that it sends output to the console. You should also configure the Python logging module or any framework specific logging mechanism to use the console.

Any logging generated and output to the console can be viewed using the `oc logs` command or via the OpenShift web console.

=== Inbound HTTP Connections

If you are not using the bundled support for hosting a WSGI application using Gunicorn, and are using an alternate WSGI server, or a custom Python web server, the server must accept inbound HTTP connections on port 8080. If the server would by default only accept HTTP connections on a local network interface, such as `localhost` or `127.0.0.1`, you must tell it to bind to the network address `0.0.0.0` so that it can accept HTTP connections on any network interface.

When connections are received from another application running in the same OpenShift project, they will be a direct connection from that other application. When an application is exposed to the Internet, inbound connections will arrive via a HTTP proxy. In this case the Python web server or application must handle proxy headers which provide details of the remote client.

* `X-Forwarded-For` - Specifies the remote client address and any proxies which the request has passed through.
* `X-Forwarded-Port` - The exposed port on which the inbound HTTP connection was accepted.
* `X-Forwarded-Proto` - The protocol scheme identifying the type of connection made: `http` or `https`.

The `Host` header will be passed through with the original hostname that the client created the connection against.

The `python` source-to-image builders do not directly support termination of TLS connections for HTTPS. If your application requires that a remote client use a secure connection, you should enable use of a secure connection when exposing the service, specifying `edge` termination, and optionally supplying your SSL certificate details.

=== Hosting of Static Files

The `python` source-to-image builders do not provide any bundled functionality for hosting static files. If you are using the Gunicorn WSGI server, you will need to use a WSGI middleware package such as link:https://pypi.python.org/pypi/whitenoise[WhiteNoise] to host static files, or host them using a separately deployed web server. If using a separate a web server, you can still have the static files available under the same exposed host name, by using a path based route when exposing the separate web server.

The alternative to using a separate web server, is to use a WSGI server such as mod_wsgi-express or uWSGI, which provide direct support for hosting static files.

=== Running With Gunicorn

Gunicorn is the default deployment option for a WSGI application. To use the bundled support for running Gunicorn, the requirements are as follows:

* The `gunicorn` package must be installed via the `requirements.txt` or `setup.py` files.
* A `wsgi.py` file must be located in the top level directory of the source code repository, or a sub directory down to at most two levels.
* The `wsgi.py` file must be part of a Python package, if in a sub directory, and will be imported by its module path, rather than by file system path.
* The name of the WSGI application entry point callable contained in the `wsgi.py` file must be called `application`.

The `APP_CONFIG` environment variable can be set to the name of a Python code file including any additional Gunicorn configuration settings. This will be supplied to Gunicorn using the `--config` option of `gunicorn`. The configuration file might be used to override the name of the WSGI application entry point callable, or set the number of Gunicorn worker processes.

The configuration file can also be used to set the type of worker, allowing you to use alternate workers such as those for `gevent` or `eventlet`. If using an alternate type of worker, you will need to ensure that any additional Python packages required for it are listed in the `requirements.txt` or `setup.py` file.

=== Running With Apache/mod_wsgi

To run your WSGI application with Apache/mod_wsgi, you can use mod_wsgi-express. This can be installed by listing `mod_wsgi` in the `requirements.txt` or `setup.py` files.

Unlike when using Apache/mod_wsgi directly, where you would need to configure Apache yourself, mod_wsgi-express will handle all configuration of Apache and mod_wsgi for you, making it very easy to deploy your WSGI application. When mod_wsgi-express configures Apache, it uses a configuration which has been set up specifically for hosting Python web applications, providing you a better baseline performance than a generic Apache configuration.

Normally `mod_wsgi-express` would be executed from the command line, it can however also be launched from Python code included in `app.py` using the Python `mod_wsgi` package. For example:

[source,python]
--
import mod_wsgi.server

mod_wsgi.server.start(
  '--log-to-terminal',
  '--port', '8080',
  '--trust-proxy-header', 'X-Forwarded-For',
  '--trust-proxy-header', 'X-Forwarded-Port',
  '--trust-proxy-header', 'X-Forwarded-Proto',
  '--url-alias', '/static/', './static/',
  '--application-type', 'module',
  '--entry-point', 'demo.wsgi',
)
--

The key options provided to mod_wsgi-express via the `mod_wsgi.server.start()` call are as follows:

* The `--log-to-terminal` option ensures that all logging from Apache is sent to the console and is available to OpenShift.
* The `--port` option ensures that Apache is listening on port 8080.
* The `--trust-proxy-header` options ensure that mod_wsgi fixes up the WSGI request details based on details passed via the HTTP proxy. This means you do not have to integrate a WSGI middleware into your application, or enable a framework specific mechanism, to make the changes.
* The `--url-alias` option indicates to Apache that it should host static files at the location specified by the first argument, from the directory given as second argument.
* The `--application-type` option indicates to mod_wsgi that the WSGI application can be found by importing a specified module.
* The `--entry-point` option indicates to mod_wsgi the module containing the WSGI application, in this case `demo.wsgi`. This could be an installed module, or a part of a local package in the source code repository where the `wsgi.py` file is located at the path `demo/wsgi.py`. If the `wsgi.py` file was located in the top level directory of the source code repository, the argument to the `--entry-point` option would instead have been `wsgi`.

For a complete list of the options that mod_wsgi-express provides, you can install the `mod_wsgi` module locally, or `oc rsh` into the running application pod, and run `mod_wsgi-express start-server --help`. Note that all options when passed to `mod_wsgi.server.start()` need to be passed as strings.

=== Running With uWSGI

To run your WSGI application with uWSGI, you will need to list `uWSGI` in the `requirements.txt` or `setup.py` files.

As uWSGI is normally paired with `nginx` and `nginx` is not being used, uWSGI will need to be configured to accept HTTP connections directly. In this mode uWSGI does not perform as well as when paired with `nginx` using its own wire protocol. Static files, when hosted by `uWSGI` directly rather than by `nginx` is also not as perfomant. You may therefore find `mod_wsgi-express` a better option for use in the containerized environment provided by OpenShift.

Running uWSGI entails running the `uwsgi` program from the command line. This can be done from an `app.py` file using `exec` functions of the `os` module, but so that it isn't necessary to hard code the path to the `uwsgi` program, it is better to use an intermediary `app.sh` script file. The `app.py` file should therefore include:

[source,python]
--
import os

os.execl('/opt/app-root/src/app.sh', 'uwsgi')
--

The `app.sh` file should then include:

[source,console]
--
#!/bin/bash

exec uwsgi \
    --http-socket :8080 \
    --die-on-term \
    --master \
    --single-interpreter \
    --enable-threads \
    --threads=5 \
    --thunder-lock \
    --static-map /static=static \
    --module demo.wsgi
--

The `app.sh` script file should be executable and placed in the top level directory of your source code repository along with the `app.py` file.

The key options provided to the `uwsgi` program are as follows:

* The `--http-socket` option and argument `:8080` ensures that uWSGI is listening on port 8080 using an INET socket.
* The `--die-on-term` option ensures that uWSGI will shutdown when it receives a `TERM` signal to stop the container, rather than restart worker processes.
* The `--master` option ensures that master mode of uWSGI is used for managing worker processes. This is required otherwise uWSGI will not correctly reap zombie processes when run as process ID 1 inside of a container.
* The `--single-interpreter` option ensures that uWSGI doesn't not use Python sub interpreters for hosting the WSGI application. This avoids problems with Python C extensions that will not work in sub interpreters.
* The `--enable-threads` option ensures that thread support in the Python interpreter is initialised. If this is not done and an application wished to create background threads, they will not run.
* The `--threads` option is used to start multiple request handler threads in each worker process, rather than the default of 1.
* The `--thunder-lock` option enables a fairer mechanism for load balancing requests when multiple worker processes are being used.
* The `--static-map` option indicates to uWSGI that it should host static files at the location specified by the first argument, from the directory given as second argument.
* The `--module` option indicates to uWSGI the module containing the WSGI application, in this case `demo.wsgi`. This could be an installed module, or a part of a local package in the source code repository where the `wsgi.py` file is located at the path `demo/wsgi.py`. If the `wsgi.py` file was located in the top level directory of the source code repository, the argument would instead have been `wsgi`.

For a complete list of options that the `uwsgi` program accepts, you can install it locally, or `oc rsh` into the running application pod and run `uwsgi --help`.
