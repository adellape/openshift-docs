// Module included in the following assemblies:
//
// * backup_and_restore/application_backup_and_restore/troubleshooting.adoc

:_content-type: CONCEPT
[id="clustertool-monitoring_{context}"]
= ClusterTool Monitoring

The {product-title} provides a monitoring stack that allows users and administrators to effectively monitor and manage their clusters, as well as monitor and analyze the workload performance of user applications and services running on the clusters, including receiving alerts if an event occurs.

[id="ClusterTool-monitoring-setup_{context}"]
== ClusterTool monitoring setup

The ClusterTool Operator leverages an OpenShift User Workload Monitoring provided by the OpenShift Monitoring Stack for retrieving metrics from the Velero service endpoint. The monitoring stack allows creating user-defined Alerting Rules or querying metrics by using the OpenShift Metrics query front end.

With enabled User Workload Monitoring, it is possible to configure and use any Prometheus-compatible third-party UI, such as Grafana, to visualize Velero metrics.

Monitoring metrics requires enabling monitoring for the user-defined projects and creating a `ServiceMonitor` resource to scrape those metrics from the already enabled ClusterTool service endpoint that resides in the `openshift-adp` namespace.

.Prerequisites
* You have access to an {product-title} cluster using an account with `cluster-admin` permissions.
* You have created a xref:../../monitoring/configuring-the-monitoring-stack.adoc#creating-cluster-monitoring-configmap_configuring-the-monitoring-stack[cluster monitoring config map].

.Procedure

. Edit the `cluster-monitoring-config` ConfigMap object in the `openshift-monitoring` namespace and add or enable the `enableUserWorkload` option under `data/config.yaml`.
+
.Example output
[source,terminal]
----
$ oc edit configmap cluster-monitoring-config -n openshift-monitoring
----
+
.Example output
[source,yaml]

----
apiVersion: v1
data:
  config.yaml: |
    enableUserWorkload: true  <1>
kind: ConfigMap
metadata:
# [...]
----
<1> Add this option or set to `true`

. Wait a short period of time to verify the User Workload Monitoring Setup by checking if the following components are up and running in the `openshift-user-workload-monitoring` namespace.
+
.Example output
[source,terminal]
----
$ oc get pods -n openshift-user-workload-monitoring
----
+
----
NAME                                   READY   STATUS    RESTARTS   AGE
prometheus-operator-6844b4b99c-b57j9   2/2     Running   0          43s
prometheus-user-workload-0             5/5     Running   0          32s
prometheus-user-workload-1             5/5     Running   0          32s
thanos-ruler-user-workload-0           3/3     Running   0          32s
thanos-ruler-user-workload-1           3/3     Running   0          32s
----
+
. Verify the existence of the `user-workload-monitoring-config` ConfigMap in the `openshift-user-workload-monitoring`. If it exists, skip the remaining steps in this procedure.
+
.Example output
[source,terminal]
----
$ oc get configmap user-workload-monitoring-config -n openshift-user-workload-monitoring
Error from server (NotFound): configmaps "user-workload-monitoring-config" not found

# We need to create: user-workload-monitoring-config ConfigMap
----
+
. Create `user-workload-monitoring-config` ConfigMap for the User Workload Monitoring and save it under `2_configure_user_workload_monitoring.yaml` filename.
+
.Example output
[source,yaml]
+
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: user-workload-monitoring-config
  namespace: openshift-user-workload-monitoring
data:
  config.yaml: |
----
+
. Apply the `2_configure_user_workload_monitoring.yaml` file:
+
.Example output
[source,terminal]
----
$ oc apply -f 2_configure_user_workload_monitoring.yaml
configmap/user-workload-monitoring-config created
----

[id="clustertool-creating-service-monitor_{context}"]
== Creating ClusterTool service monitor

ClusterTool provides an `openshift-adp-velero-metrics-svc` service which is created when the DPA is configured. The service monitor used by the user workload monitoring must point to the defined SVC service.

Get details about the service by running the following command:

.Procedure

. Ensure the `openshift-adp-velero-metrics-svc` exists. It should contain `app.kubernetes.io/name=velero` label which will be used as selector for the `ServiceMonitor`.

+
[source,terminal]
----
$ oc get svc -n openshift-adp -l app.kubernetes.io/name=velero
----
+
----
NAME                               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
openshift-adp-velero-metrics-svc   ClusterIP   172.30.38.244   <none>        8085/TCP   1h
----
+
. Create a `ServiceMonitor` YAML file that matches the existing SVC label, and save the file as `3_create_clustertool_service_monitor.yaml`. The service monitor is created in the `openshift-adp` namespace where the `openshift-adp-velero-metrics-svc` service resides.
+
.Example output
[source,yaml]
+
----
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app: clustertool-service-monitor
  name: clustertool-service-monitor
  namespace: openshift-adp
spec:
  endpoints:
  - interval: 30s
    path: /metrics
    targetPort: 8085
    scheme: http
  selector:
    matchLabels:
      app.kubernetes.io/name: "velero"
----
+
. Apply the `3_create_clustertool_service_monitor.yaml` file:
+
[source,terminal]
----
$ oc apply -f 3_create_clustertool_service_monitor.yaml
servicemonitor.monitoring.coreos.com/clustertool-service-monitor created
----
+
. Confirm that the new ServiceMonitor is `Up`.
In the *Administrator* perspective of the OpenShift Container Platform web console use *Observe/Targets* to view the Metrics Targets. Ensure the `Filter` is unselected or that the `User` source is selected, and type `openshift-adp` in the `Text` search field. Ensure the status for the ServiceMonitor is `Up`.
+
.ClusterTool metrics targets

image::olm-workflow.png[ClusterTool metrics targets]

[id="creating-alerting-rules_{context}"]
==  Creating an alerting rule

The {product-title} }monitoring stack allows to receive Alerts configured using Alerting Rules. To create an Alerting rule for the ClusterTool project, use one of the Metrics which are scraped with the user workload monitoring.

Refer to xref:../../monitoring/managing-alerts.adoc#managing-alerts[managing alerts] in the {product-title} documentation for detailed instructions on how to create and manage OpenShift Alerts.

.Procedure

. Create a `PrometheusRule` YAML file with the sample `ClusterToolBackupFailing` alert and save it as `4_create_clustertool_alert_rule.yaml`.
. In this example, an Alert displays when there is an increase of failing backups, which indicates new failures, during the 2 last hours that is greater than 0 and this state persisted for at least 5 minutes. If the time of the first increase is less than 5 minutes, the Alert will be in a `Pending` state, after which it will turn into a `Firing` state.
+
.Example output
[source,yaml]
+
----
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sample-clustertool-alert
  namespace: openshift-adp
spec:
  groups:
  - name: sample-clustertool-backup-alert
    rules:
    - alert: ClusterToolBackupFailing
      annotations:
        description: 'ClusterTool had {{$value | humanize}} backup failures over the last 2 hours.'
        summary: ClusterTool has issues creating backups
      expr: |
        increase(velero_backup_failure_total{job="openshift-adp-velero-metrics-svc"}[2h]) > 0
      for: 5m
      labels:
        severity: warning
----
+
. Apply the `4_create_clustertool_alert_rule.yaml` file, which creates the PrometheusRule in the `openshift-adp` namespace:
+
[source,terminal]
----
$ oc apply -f 4_create_clustertool_alert_rule.yaml
prometheusrule.monitoring.coreos.com/sample-clustertool-alert created
----

.Verification
. After the Alert is triggered, it can be viewed in the following ways:
* In the *Administrator* view under *Observe* -> *Alerting* menu, select *User* in the *Filter* box. Otherwise, by default only the *Platform* Alerts are displayed.
* In the *Developer* view, select the *Observe* menu.
+
.ClusterTool backup failing alert

image::olm-workflow.png[ClusterTool backup failing alert]

[id=list-of-metrics_{context}"]
== List of available metrics

These are the list of metrics provided by the ClusterTool together with their https://prometheus.io/docs/concepts/metric_types/[Types].

|===
|Metric name |Description |Type

|`kopia_content_cache_hit_bytes`
|Number of bytes retrieved from the cache
|Counter

|`kopia_content_cache_hit_count`
|Number of times content was retrieved from the cache
|Counter

|`kopia_content_cache_malformed`
|Number of times malformed content was read from the cache
|Counter

|`kopia_content_cache_miss_count`
|Number of times content was not found in the cache and fetched
|Counter

|`kopia_content_cache_missed_bytes`
|Number of bytes retrieved from the underlying storage
|Counter

|`kopia_content_cache_miss_error_count`
|Number of times content could not be found in the underlying storage
|Counter

|`kopia_content_cache_store_error_count`
|Number of times content could not be saved in the cache
|Counter

|`kopia_content_get_bytes`
|Number of bytes retrieved using GetContent
|Counter

|`kopia_content_get_count`
|Number of times GetContent() was called
|Counter

|`kopia_content_get_error_count`
|Number of times GetContent() was called and the result was an error
|Counter

|`kopia_content_get_not_found_count`
|Number of times GetContent() was called and the result was not found
|Counter

|`kopia_content_write_bytes`
|Number of bytes passed to WriteContent()
|Counter

|`kopia_content_write_count`
|Number of times WriteContent() was called
|Counter

|`velero_backup_attempt_total`
|Total number of attempted backups
|Counter

|`velero_backup_deletion_attempt_total`
|Total number of attempted backup deletions
|Counter

|`velero_backup_deletion_failure_total`
|Total number of failed backup deletions
|Counter

|`velero_backup_deletion_success_total`
|Total number of successful backup deletions
|Counter

|`velero_backup_duration_seconds`
|Time taken to complete backup, in seconds
|Histogram

|`velero_backup_failure_total`
|Total number of failed backups
|Counter

|`velero_backup_items_errors`
|Total number of errors encountered during backup
|Gauge

|`velero_backup_items_total`
|Total number of items backed up
|Gauge

|`velero_backup_last_status`
|Last status of the backup. A value of 1 is success, 0.
|Gauge

|`velero_backup_last_successful_timestamp`
|Last time a backup ran successfully, Unix timestamp in seconds
|Gauge

|`velero_backup_partial_failure_total`
|Total number of partially failed backups
|Counter

|`velero_backup_success_total`
|Total number of successful backups
|Counter

|`velero_backup_tarball_size_bytes`
|Size, in bytes, of a backup
|Gauge

|`velero_backup_total`
|Current number of existent backups
|Gauge

|`velero_backup_validation_failure_total`
|Total number of validation failed backups
|Counter

|`velero_backup_warning_total`
|Total number of warned backups
|Counter

|`velero_csi_snapshot_attempt_total`
|Total number of CSI attempted volume snapshots
|Counter

|`velero_csi_snapshot_failure_total`
|Total number of CSI failed volume snapshots
|Counter

|`velero_csi_snapshot_success_total`
|Total number of CSI successful volume snapshots
|Counter

|`velero_restore_attempt_total`
|Total number of attempted restores
|Counter

|`velero_restore_failed_total`
|Total number of failed restores
|Counter

|`velero_restore_partial_failure_total`
|Total number of partially failed restores
|Counter

|`velero_restore_success_total`
|Total number of successful restores
|Counter

|`velero_restore_total`
|Current number of existent restores
|Gauge

|`velero_restore_validation_failed_total`
|Total number of failed restores failing validations
|Counter

|`velero_volume_snapshot_attempt_total`
|Total number of attempted volume snapshots
|Counter

|`velero_volume_snapshot_failure_total`
|Total number of failed volume snapshots
|Counter

|`velero_volume_snapshot_success_total`
|Total number of successful volume snapshots
|Counter

|===

[id="viewing-metrics-observe-ui_{context}"]
== Viewing metrics using the Observe UI

You can view metrics in the {product-title} web console from the *Administrator* or *Developer* perspective, which must have access to the `openshift-adp` project.

.Procedure

. Select *Observe* and then select *Metrics*.
.. In the *Developer* view select *Custom query*, or click on the *Show PromQL* link, type the query and click *Enter*.
.. In the *Administrator* view type the Expression in the text field and select *Run Queries*.
+
.ClusterTool metrics query

image::olm-workflow.png[]


